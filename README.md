# Safety in AI
## Robustness metric for Deep Learning predictions
Portfolio Project for the Data Science Retreat

How reliable are predictions of Deep Learning algorithms? In this project an extension of WGAN is used in order to produce a meaningful measure of robustness. This approach is applicable to every black box classifier and it doesnâ€™t need any modification of the used classifier.
Using this approach is possible to create an alarm system that alerts the user if an online prediction is weak. This is particularly important in scenarios where AI could affect the safety of people or environment. Such a system is explored and implemented for an experimental scenario.
